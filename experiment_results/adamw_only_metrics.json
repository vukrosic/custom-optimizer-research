{
  "experiment_name": "adamw_only",
  "start_time": "2025-12-06T08:18:28.762275",
  "steps": [
    {
      "step": 2,
      "train_loss": 10.708874225616455,
      "tokens_per_sec": 88646.15793119551,
      "lr_embedding": 0.0003,
      "lr_attention": 0.0003,
      "lr_ffn": 0.0003,
      "lr_norm": 0.0003
    },
    {
      "step": 4,
      "train_loss": 10.162477970123291,
      "tokens_per_sec": 89373.86670551008,
      "lr_embedding": 0.0002909539103507995,
      "lr_attention": 0.0002909539103507995,
      "lr_ffn": 0.0002909539103507995,
      "lr_norm": 0.0002909539103507995
    },
    {
      "step": 6,
      "train_loss": 9.780019283294678,
      "tokens_per_sec": 89484.54418267903,
      "lr_embedding": 0.00026490672826766967,
      "lr_attention": 0.00026490672826766967,
      "lr_ffn": 0.00026490672826766967,
      "lr_norm": 0.00026490672826766967
    },
    {
      "step": 8,
      "train_loss": 9.529677867889404,
      "tokens_per_sec": 89629.38480540806,
      "lr_embedding": 0.0002250001162290573,
      "lr_attention": 0.0002250001162290573,
      "lr_ffn": 0.0002250001162290573,
      "lr_norm": 0.0002250001162290573
    },
    {
      "step": 10,
      "train_loss": 9.342950820922852,
      "tokens_per_sec": 89513.33492596727,
      "lr_embedding": 0.00017604740783572196,
      "lr_attention": 0.00017604740783572196,
      "lr_ffn": 0.00017604740783572196,
      "lr_norm": 0.00017604740783572196,
      "token_embedding.weight_spectral": 6.954151153564453,
      "layers.0.attention.qkv.weight_spectral": 1.1017080545425415,
      "layers.0.attention.out_proj.weight_spectral": 0.8022475838661194,
      "layers.0.feed_forward.w1.weight_spectral": 1.1993999481201172,
      "layers.0.feed_forward.w2.weight_spectral": 1.202003002166748,
      "layers.0.feed_forward.w3.weight_spectral": 1.1897052526474,
      "layers.1.attention.qkv.weight_spectral": 1.0917589664459229,
      "layers.1.attention.out_proj.weight_spectral": 0.8457387685775757,
      "layers.1.feed_forward.w1.weight_spectral": 1.2157368659973145,
      "layers.1.feed_forward.w2.weight_spectral": 1.1910531520843506,
      "layers.1.feed_forward.w3.weight_spectral": 1.204140543937683,
      "layers.2.attention.qkv.weight_spectral": 1.0907156467437744,
      "layers.2.attention.out_proj.weight_spectral": 0.7962355613708496,
      "layers.2.feed_forward.w1.weight_spectral": 1.1837458610534668,
      "layers.2.feed_forward.w2.weight_spectral": 1.193801760673523,
      "layers.2.feed_forward.w3.weight_spectral": 1.2158737182617188,
      "layers.3.attention.qkv.weight_spectral": 1.1393580436706543,
      "layers.3.attention.out_proj.weight_spectral": 0.8053430318832397,
      "layers.3.feed_forward.w1.weight_spectral": 1.2189695835113525,
      "layers.3.feed_forward.w2.weight_spectral": 1.2241514921188354,
      "layers.3.feed_forward.w3.weight_spectral": 1.1991541385650635,
      "embedding_frob_mean": 100.51911163330078,
      "embedding_frob_max": 100.51911163330078,
      "attention_frob_mean": 13.997912764549255,
      "attention_frob_max": 17.764543533325195,
      "ffn_frob_mean": 20.49592097600301,
      "ffn_frob_max": 20.529817581176758,
      "norm_frob_mean": 22.624663458930122,
      "norm_frob_max": 22.642295837402344
    },
    {
      "step": 12,
      "train_loss": 9.10360050201416,
      "tokens_per_sec": 89746.32201309115,
      "lr_embedding": 0.00012395298331975937,
      "lr_attention": 0.00012395298331975937,
      "lr_ffn": 0.00012395298331975937,
      "lr_norm": 0.00012395298331975937
    },
    {
      "step": 14,
      "train_loss": 9.00490427017212,
      "tokens_per_sec": 89731.43919512689,
      "lr_embedding": 7.500024139881133e-05,
      "lr_attention": 7.500024139881133e-05,
      "lr_ffn": 7.500024139881133e-05,
      "lr_norm": 7.500024139881133e-05
    },
    {
      "step": 16,
      "train_loss": 8.88700819015503,
      "tokens_per_sec": 89643.18133445692,
      "lr_embedding": 3.509353995323181e-05,
      "lr_attention": 3.509353995323181e-05,
      "lr_ffn": 3.509353995323181e-05,
      "lr_norm": 3.509353995323181e-05
    },
    {
      "step": 18,
      "train_loss": 8.864068984985352,
      "tokens_per_sec": 89298.95722141943,
      "lr_embedding": 9.046232700347899e-06,
      "lr_attention": 9.046232700347899e-06,
      "lr_ffn": 9.046232700347899e-06,
      "lr_norm": 9.046232700347899e-06
    },
    {
      "step": 20,
      "train_loss": 8.827809810638428,
      "tokens_per_sec": 89382.46900920235,
      "lr_embedding": 0.0,
      "lr_attention": 0.0,
      "lr_ffn": 0.0,
      "lr_norm": 0.0,
      "token_embedding.weight_spectral": 11.591146469116211,
      "layers.0.attention.qkv.weight_spectral": 1.086107850074768,
      "layers.0.attention.out_proj.weight_spectral": 0.8099139928817749,
      "layers.0.feed_forward.w1.weight_spectral": 1.2079758644104004,
      "layers.0.feed_forward.w2.weight_spectral": 1.2089078426361084,
      "layers.0.feed_forward.w3.weight_spectral": 1.1888514757156372,
      "layers.1.attention.qkv.weight_spectral": 1.0982961654663086,
      "layers.1.attention.out_proj.weight_spectral": 0.8050229549407959,
      "layers.1.feed_forward.w1.weight_spectral": 1.2173733711242676,
      "layers.1.feed_forward.w2.weight_spectral": 1.2162153720855713,
      "layers.1.feed_forward.w3.weight_spectral": 1.2216572761535645,
      "layers.2.attention.qkv.weight_spectral": 1.102318286895752,
      "layers.2.attention.out_proj.weight_spectral": 0.8452790975570679,
      "layers.2.feed_forward.w1.weight_spectral": 1.2011439800262451,
      "layers.2.feed_forward.w2.weight_spectral": 1.199612021446228,
      "layers.2.feed_forward.w3.weight_spectral": 1.192385196685791,
      "layers.3.attention.qkv.weight_spectral": 1.121553659439087,
      "layers.3.attention.out_proj.weight_spectral": 0.8468246459960938,
      "layers.3.feed_forward.w1.weight_spectral": 1.1955147981643677,
      "layers.3.feed_forward.w2.weight_spectral": 1.2155643701553345,
      "layers.3.feed_forward.w3.weight_spectral": 1.2140718698501587,
      "embedding_frob_mean": 100.755859375,
      "embedding_frob_max": 100.755859375,
      "attention_frob_mean": 14.00316071510315,
      "attention_frob_max": 17.772066116333008,
      "ffn_frob_mean": 20.50179688135783,
      "ffn_frob_max": 20.534976959228516,
      "norm_frob_mean": 22.62525177001953,
      "norm_frob_max": 22.655975341796875
    },
    {
      "step": 20,
      "val_loss": 8.790955734252929,
      "perplexity": 6574.5126606974845
    }
  ],
  "config": {
    "name": "adamw_only",
    "description": "AdamW for all parameters (no Muon)",
    "max_steps": 20,
    "batch_size": 16,
    "hidden_size": 512,
    "num_layers": 4,
    "embedding_optimizer": "adamw",
    "embedding_lr": 0.0003,
    "attention_optimizer": "adamw",
    "attention_lr": 0.0003,
    "ffn_optimizer": "adamw",
    "ffn_lr": 0.0003
  },
  "final_val_loss": 8.794533273007007,
  "final_perplexity": 6598.075357629868,
  "end_time": "2025-12-06T08:19:20.054793"
}