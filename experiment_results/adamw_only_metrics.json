{
  "experiment_name": "adamw_only",
  "start_time": "2025-12-06T08:36:55.384009",
  "steps": [
    {
      "step": 20,
      "train_loss": 9.864110612869263,
      "tokens_per_sec": 89522.73380957567,
      "lr_embedding": 0.0003,
      "lr_attention": 0.0003,
      "lr_ffn": 0.0003,
      "lr_norm": 0.0003
    },
    {
      "step": 40,
      "train_loss": 8.052467727661133,
      "tokens_per_sec": 89619.50769668157,
      "lr_embedding": 0.0002909539103507995,
      "lr_attention": 0.0002909539103507995,
      "lr_ffn": 0.0002909539103507995,
      "lr_norm": 0.0002909539103507995
    },
    {
      "step": 60,
      "train_loss": 7.548315834999085,
      "tokens_per_sec": 89454.09511521208,
      "lr_embedding": 0.00026490672826766967,
      "lr_attention": 0.00026490672826766967,
      "lr_ffn": 0.00026490672826766967,
      "lr_norm": 0.00026490672826766967
    },
    {
      "step": 80,
      "train_loss": 7.3751297235488895,
      "tokens_per_sec": 89303.83122590974,
      "lr_embedding": 0.0002250001162290573,
      "lr_attention": 0.0002250001162290573,
      "lr_ffn": 0.0002250001162290573,
      "lr_norm": 0.0002250001162290573
    },
    {
      "step": 100,
      "train_loss": 7.229121685028076,
      "tokens_per_sec": 89179.45547170477,
      "lr_embedding": 0.00017604740783572196,
      "lr_attention": 0.00017604740783572196,
      "lr_ffn": 0.00017604740783572196,
      "lr_norm": 0.00017604740783572196,
      "token_embedding.weight_spectral": 51.90452575683594,
      "layers.0.attention.qkv.weight_spectral": 1.4330908060073853,
      "layers.0.attention.out_proj.weight_spectral": 0.8303026556968689,
      "layers.0.feed_forward.w1.weight_spectral": 1.7163832187652588,
      "layers.0.feed_forward.w2.weight_spectral": 1.8392072916030884,
      "layers.0.feed_forward.w3.weight_spectral": 1.421541452407837,
      "layers.1.attention.qkv.weight_spectral": 1.7291686534881592,
      "layers.1.attention.out_proj.weight_spectral": 0.79655921459198,
      "layers.1.feed_forward.w1.weight_spectral": 1.57711923122406,
      "layers.1.feed_forward.w2.weight_spectral": 1.49880051612854,
      "layers.1.feed_forward.w3.weight_spectral": 1.3920501470565796,
      "layers.2.attention.qkv.weight_spectral": 1.8562958240509033,
      "layers.2.attention.out_proj.weight_spectral": 0.8067238926887512,
      "layers.2.feed_forward.w1.weight_spectral": 1.2396016120910645,
      "layers.2.feed_forward.w2.weight_spectral": 1.5762572288513184,
      "layers.2.feed_forward.w3.weight_spectral": 1.2407673597335815,
      "layers.3.attention.qkv.weight_spectral": 2.351489543914795,
      "layers.3.attention.out_proj.weight_spectral": 0.9245221018791199,
      "layers.3.feed_forward.w1.weight_spectral": 1.264264464378357,
      "layers.3.feed_forward.w2.weight_spectral": 1.3139925003051758,
      "layers.3.feed_forward.w3.weight_spectral": 1.3381973505020142,
      "embedding_frob_mean": 112.76115417480469,
      "embedding_frob_max": 112.76115417480469,
      "attention_frob_mean": 14.058538317680359,
      "attention_frob_max": 17.92496109008789,
      "ffn_frob_mean": 20.594732920328777,
      "ffn_frob_max": 20.66385269165039,
      "norm_frob_mean": 22.648585425482857,
      "norm_frob_max": 22.91171646118164
    },
    {
      "step": 120,
      "train_loss": 7.146046042442322,
      "tokens_per_sec": 89058.43796375506,
      "lr_embedding": 0.00012395298331975937,
      "lr_attention": 0.00012395298331975937,
      "lr_ffn": 0.00012395298331975937,
      "lr_norm": 0.00012395298331975937
    },
    {
      "step": 140,
      "train_loss": 6.993788337707519,
      "tokens_per_sec": 88956.77930511955,
      "lr_embedding": 7.500024139881133e-05,
      "lr_attention": 7.500024139881133e-05,
      "lr_ffn": 7.500024139881133e-05,
      "lr_norm": 7.500024139881133e-05
    },
    {
      "step": 160,
      "train_loss": 6.963560652732849,
      "tokens_per_sec": 88910.47704612098,
      "lr_embedding": 3.509353995323181e-05,
      "lr_attention": 3.509353995323181e-05,
      "lr_ffn": 3.509353995323181e-05,
      "lr_norm": 3.509353995323181e-05
    },
    {
      "step": 180,
      "train_loss": 6.921462345123291,
      "tokens_per_sec": 88880.30238157566,
      "lr_embedding": 9.046232700347899e-06,
      "lr_attention": 9.046232700347899e-06,
      "lr_ffn": 9.046232700347899e-06,
      "lr_norm": 9.046232700347899e-06
    },
    {
      "step": 200,
      "train_loss": 6.911408996582031,
      "tokens_per_sec": 88723.1486628873,
      "lr_embedding": 0.0,
      "lr_attention": 0.0,
      "lr_ffn": 0.0,
      "lr_norm": 0.0,
      "token_embedding.weight_spectral": 61.7100944519043,
      "layers.0.attention.qkv.weight_spectral": 1.3539378643035889,
      "layers.0.attention.out_proj.weight_spectral": 0.8049836754798889,
      "layers.0.feed_forward.w1.weight_spectral": 1.4273450374603271,
      "layers.0.feed_forward.w2.weight_spectral": 1.2940990924835205,
      "layers.0.feed_forward.w3.weight_spectral": 1.4581729173660278,
      "layers.1.attention.qkv.weight_spectral": 1.784726858139038,
      "layers.1.attention.out_proj.weight_spectral": 0.83335280418396,
      "layers.1.feed_forward.w1.weight_spectral": 1.3768123388290405,
      "layers.1.feed_forward.w2.weight_spectral": 1.4445414543151855,
      "layers.1.feed_forward.w3.weight_spectral": 1.4353874921798706,
      "layers.2.attention.qkv.weight_spectral": 1.5321261882781982,
      "layers.2.attention.out_proj.weight_spectral": 1.0877838134765625,
      "layers.2.feed_forward.w1.weight_spectral": 1.4334826469421387,
      "layers.2.feed_forward.w2.weight_spectral": 1.3277734518051147,
      "layers.2.feed_forward.w3.weight_spectral": 1.3562219142913818,
      "layers.3.attention.qkv.weight_spectral": 1.6368916034698486,
      "layers.3.attention.out_proj.weight_spectral": 1.0635708570480347,
      "layers.3.feed_forward.w1.weight_spectral": 1.2653658390045166,
      "layers.3.feed_forward.w2.weight_spectral": 1.4801983833312988,
      "layers.3.feed_forward.w3.weight_spectral": 1.2315560579299927,
      "embedding_frob_mean": 117.62408447265625,
      "embedding_frob_max": 117.62408447265625,
      "attention_frob_mean": 14.0936918258667,
      "attention_frob_max": 17.984554290771484,
      "ffn_frob_mean": 20.616267681121826,
      "ffn_frob_max": 20.6875057220459,
      "norm_frob_mean": 22.667556762695312,
      "norm_frob_max": 23.01981544494629
    },
    {
      "step": 200,
      "val_loss": 6.860405826568604,
      "perplexity": 953.7540476949166
    }
  ],
  "config": {
    "name": "adamw_only",
    "description": "AdamW for all parameters (no Muon)",
    "max_steps": 200,
    "batch_size": 16,
    "hidden_size": 512,
    "num_layers": 4,
    "embedding_optimizer": "adamw",
    "embedding_lr": 0.0003,
    "attention_optimizer": "adamw",
    "attention_lr": 0.0003,
    "ffn_optimizer": "adamw",
    "ffn_lr": 0.0003
  },
  "final_val_loss": 6.871893651941989,
  "final_perplexity": 964.7737828511715,
  "end_time": "2025-12-06T08:38:03.400840"
}