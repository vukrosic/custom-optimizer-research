{
  "experiment_name": "stiefel_all",
  "start_time": "2025-12-06T08:19:20.393818",
  "steps": [
    {
      "step": 2,
      "train_loss": 10.763702869415283,
      "tokens_per_sec": 53633.08101138775,
      "lr_embedding": 0.0003,
      "lr_attention": 0.0003,
      "lr_ffn": 0.0003,
      "lr_norm": 0.0003
    },
    {
      "step": 4,
      "train_loss": 10.364771842956543,
      "tokens_per_sec": 59848.493617970016,
      "lr_embedding": 0.0002909539103507995,
      "lr_attention": 0.0002909539103507995,
      "lr_ffn": 0.0002909539103507995,
      "lr_norm": 0.0002909539103507995
    },
    {
      "step": 6,
      "train_loss": 9.995111465454102,
      "tokens_per_sec": 59708.81887897403,
      "lr_embedding": 0.00026490672826766967,
      "lr_attention": 0.00026490672826766967,
      "lr_ffn": 0.00026490672826766967,
      "lr_norm": 0.00026490672826766967
    },
    {
      "step": 8,
      "train_loss": 9.697819709777832,
      "tokens_per_sec": 59731.083552009986,
      "lr_embedding": 0.0002250001162290573,
      "lr_attention": 0.0002250001162290573,
      "lr_ffn": 0.0002250001162290573,
      "lr_norm": 0.0002250001162290573
    },
    {
      "step": 10,
      "train_loss": 9.496267318725586,
      "tokens_per_sec": 59820.88135144687,
      "lr_embedding": 0.00017604740783572196,
      "lr_attention": 0.00017604740783572196,
      "lr_ffn": 0.00017604740783572196,
      "lr_norm": 0.00017604740783572196,
      "token_embedding.weight_spectral": 6.437532424926758,
      "layers.0.attention.qkv.weight_spectral": 1.0688953399658203,
      "layers.0.attention.out_proj.weight_spectral": 1.0656497478485107,
      "layers.0.feed_forward.w1.weight_spectral": 1.0659921169281006,
      "layers.0.feed_forward.w2.weight_spectral": 1.0660655498504639,
      "layers.0.feed_forward.w3.weight_spectral": 1.0665634870529175,
      "layers.1.attention.qkv.weight_spectral": 1.0641666650772095,
      "layers.1.attention.out_proj.weight_spectral": 1.0681195259094238,
      "layers.1.feed_forward.w1.weight_spectral": 1.0658082962036133,
      "layers.1.feed_forward.w2.weight_spectral": 1.0678553581237793,
      "layers.1.feed_forward.w3.weight_spectral": 1.068305253982544,
      "layers.2.attention.qkv.weight_spectral": 1.0649597644805908,
      "layers.2.attention.out_proj.weight_spectral": 1.0661704540252686,
      "layers.2.feed_forward.w1.weight_spectral": 1.0673084259033203,
      "layers.2.feed_forward.w2.weight_spectral": 1.064355492591858,
      "layers.2.feed_forward.w3.weight_spectral": 1.0671918392181396,
      "layers.3.attention.qkv.weight_spectral": 1.0656678676605225,
      "layers.3.attention.out_proj.weight_spectral": 1.065935492515564,
      "layers.3.feed_forward.w1.weight_spectral": 1.0677045583724976,
      "layers.3.feed_forward.w2.weight_spectral": 1.0663963556289673,
      "layers.3.feed_forward.w3.weight_spectral": 1.0687980651855469,
      "embedding_frob_mean": 100.5159912109375,
      "embedding_frob_max": 100.5159912109375,
      "attention_frob_mean": 21.39422845840454,
      "attention_frob_max": 21.426109313964844,
      "ffn_frob_mean": 21.408302783966064,
      "ffn_frob_max": 21.426868438720703,
      "norm_frob_mean": 22.625321282280815,
      "norm_frob_max": 22.633413314819336
    },
    {
      "step": 12,
      "train_loss": 9.269821643829346,
      "tokens_per_sec": 59769.63183470335,
      "lr_embedding": 0.00012395298331975937,
      "lr_attention": 0.00012395298331975937,
      "lr_ffn": 0.00012395298331975937,
      "lr_norm": 0.00012395298331975937
    },
    {
      "step": 14,
      "train_loss": 9.155789852142334,
      "tokens_per_sec": 59882.54908498036,
      "lr_embedding": 7.500024139881133e-05,
      "lr_attention": 7.500024139881133e-05,
      "lr_ffn": 7.500024139881133e-05,
      "lr_norm": 7.500024139881133e-05
    },
    {
      "step": 16,
      "train_loss": 9.039613246917725,
      "tokens_per_sec": 59804.534401793455,
      "lr_embedding": 3.509353995323181e-05,
      "lr_attention": 3.509353995323181e-05,
      "lr_ffn": 3.509353995323181e-05,
      "lr_norm": 3.509353995323181e-05
    },
    {
      "step": 18,
      "train_loss": 9.012897968292236,
      "tokens_per_sec": 59633.481032035015,
      "lr_embedding": 9.046232700347899e-06,
      "lr_attention": 9.046232700347899e-06,
      "lr_ffn": 9.046232700347899e-06,
      "lr_norm": 9.046232700347899e-06
    },
    {
      "step": 20,
      "train_loss": 8.97750997543335,
      "tokens_per_sec": 59420.98404735038,
      "lr_embedding": 0.0,
      "lr_attention": 0.0,
      "lr_ffn": 0.0,
      "lr_norm": 0.0,
      "token_embedding.weight_spectral": 11.351366996765137,
      "layers.0.attention.qkv.weight_spectral": 1.0701706409454346,
      "layers.0.attention.out_proj.weight_spectral": 1.0702061653137207,
      "layers.0.feed_forward.w1.weight_spectral": 1.0694912672042847,
      "layers.0.feed_forward.w2.weight_spectral": 1.0697734355926514,
      "layers.0.feed_forward.w3.weight_spectral": 1.0693899393081665,
      "layers.1.attention.qkv.weight_spectral": 1.0692517757415771,
      "layers.1.attention.out_proj.weight_spectral": 1.0727847814559937,
      "layers.1.feed_forward.w1.weight_spectral": 1.0704680681228638,
      "layers.1.feed_forward.w2.weight_spectral": 1.071124792098999,
      "layers.1.feed_forward.w3.weight_spectral": 1.073370099067688,
      "layers.2.attention.qkv.weight_spectral": 1.0672495365142822,
      "layers.2.attention.out_proj.weight_spectral": 1.0719878673553467,
      "layers.2.feed_forward.w1.weight_spectral": 1.069993019104004,
      "layers.2.feed_forward.w2.weight_spectral": 1.069717526435852,
      "layers.2.feed_forward.w3.weight_spectral": 1.0703402757644653,
      "layers.3.attention.qkv.weight_spectral": 1.070464849472046,
      "layers.3.attention.out_proj.weight_spectral": 1.071462869644165,
      "layers.3.feed_forward.w1.weight_spectral": 1.0709532499313354,
      "layers.3.feed_forward.w2.weight_spectral": 1.0708870887756348,
      "layers.3.feed_forward.w3.weight_spectral": 1.0719274282455444,
      "embedding_frob_mean": 100.73094940185547,
      "embedding_frob_max": 100.73094940185547,
      "attention_frob_mean": 21.44029974937439,
      "attention_frob_max": 21.470964431762695,
      "ffn_frob_mean": 21.45052973429362,
      "ffn_frob_max": 21.459590911865234,
      "norm_frob_mean": 22.626603656344944,
      "norm_frob_max": 22.643898010253906
    },
    {
      "step": 20,
      "val_loss": 8.938547706604004,
      "perplexity": 7620.1223623580745
    }
  ],
  "config": {
    "name": "stiefel_all",
    "description": "Stiefel manifold (W^T W = I) for attention & FFN",
    "max_steps": 20,
    "batch_size": 16,
    "hidden_size": 512,
    "num_layers": 4,
    "embedding_optimizer": "adamw",
    "embedding_lr": 0.0003,
    "attention_optimizer": "adamw",
    "attention_lr": 0.0003,
    "ffn_optimizer": "adamw",
    "ffn_lr": 0.0003
  },
  "final_val_loss": 8.938130789614739,
  "final_perplexity": 7616.9460660568875,
  "end_time": "2025-12-06T08:20:12.402687"
}