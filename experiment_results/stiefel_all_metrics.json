{
  "experiment_name": "stiefel_all",
  "start_time": "2025-12-06T08:38:03.751349",
  "steps": [
    {
      "step": 20,
      "train_loss": 10.014872360229493,
      "tokens_per_sec": 58831.95988027023,
      "lr_embedding": 0.0003,
      "lr_attention": 0.0003,
      "lr_ffn": 0.0003,
      "lr_norm": 0.0003
    },
    {
      "step": 40,
      "train_loss": 8.210621666908263,
      "tokens_per_sec": 59611.87338071033,
      "lr_embedding": 0.0002909539103507995,
      "lr_attention": 0.0002909539103507995,
      "lr_ffn": 0.0002909539103507995,
      "lr_norm": 0.0002909539103507995
    },
    {
      "step": 60,
      "train_loss": 7.645138120651245,
      "tokens_per_sec": 59558.26595724304,
      "lr_embedding": 0.00026490672826766967,
      "lr_attention": 0.00026490672826766967,
      "lr_ffn": 0.00026490672826766967,
      "lr_norm": 0.00026490672826766967
    },
    {
      "step": 80,
      "train_loss": 7.544059085845947,
      "tokens_per_sec": 59385.5165952759,
      "lr_embedding": 0.0002250001162290573,
      "lr_attention": 0.0002250001162290573,
      "lr_ffn": 0.0002250001162290573,
      "lr_norm": 0.0002250001162290573
    },
    {
      "step": 100,
      "train_loss": 7.391788363456726,
      "tokens_per_sec": 59371.03267332378,
      "lr_embedding": 0.00017604740783572196,
      "lr_attention": 0.00017604740783572196,
      "lr_ffn": 0.00017604740783572196,
      "lr_norm": 0.00017604740783572196,
      "token_embedding.weight_spectral": 50.308135986328125,
      "layers.0.attention.qkv.weight_spectral": 1.0717264413833618,
      "layers.0.attention.out_proj.weight_spectral": 1.069554090499878,
      "layers.0.feed_forward.w1.weight_spectral": 1.069068431854248,
      "layers.0.feed_forward.w2.weight_spectral": 1.0713419914245605,
      "layers.0.feed_forward.w3.weight_spectral": 1.0698332786560059,
      "layers.1.attention.qkv.weight_spectral": 1.0689789056777954,
      "layers.1.attention.out_proj.weight_spectral": 1.0718605518341064,
      "layers.1.feed_forward.w1.weight_spectral": 1.071242094039917,
      "layers.1.feed_forward.w2.weight_spectral": 1.071683645248413,
      "layers.1.feed_forward.w3.weight_spectral": 1.0713374614715576,
      "layers.2.attention.qkv.weight_spectral": 1.0701740980148315,
      "layers.2.attention.out_proj.weight_spectral": 1.069478988647461,
      "layers.2.feed_forward.w1.weight_spectral": 1.0718005895614624,
      "layers.2.feed_forward.w2.weight_spectral": 1.0712635517120361,
      "layers.2.feed_forward.w3.weight_spectral": 1.071486234664917,
      "layers.3.attention.qkv.weight_spectral": 1.0707032680511475,
      "layers.3.attention.out_proj.weight_spectral": 1.0706489086151123,
      "layers.3.feed_forward.w1.weight_spectral": 1.0719068050384521,
      "layers.3.feed_forward.w2.weight_spectral": 1.0693854093551636,
      "layers.3.feed_forward.w3.weight_spectral": 1.072155237197876,
      "embedding_frob_mean": 112.01680755615234,
      "embedding_frob_max": 112.01680755615234,
      "attention_frob_mean": 21.44101309776306,
      "attention_frob_max": 21.470109939575195,
      "ffn_frob_mean": 21.45068057378133,
      "ffn_frob_max": 21.45992088317871,
      "norm_frob_mean": 22.70511606004503,
      "norm_frob_max": 22.864126205444336
    },
    {
      "step": 120,
      "train_loss": 7.30278525352478,
      "tokens_per_sec": 59201.91109910753,
      "lr_embedding": 0.00012395298331975937,
      "lr_attention": 0.00012395298331975937,
      "lr_ffn": 0.00012395298331975937,
      "lr_norm": 0.00012395298331975937
    },
    {
      "step": 140,
      "train_loss": 7.154437923431397,
      "tokens_per_sec": 58953.90908143328,
      "lr_embedding": 7.500024139881133e-05,
      "lr_attention": 7.500024139881133e-05,
      "lr_ffn": 7.500024139881133e-05,
      "lr_norm": 7.500024139881133e-05
    },
    {
      "step": 160,
      "train_loss": 7.133500504493713,
      "tokens_per_sec": 58872.66952236699,
      "lr_embedding": 3.509353995323181e-05,
      "lr_attention": 3.509353995323181e-05,
      "lr_ffn": 3.509353995323181e-05,
      "lr_norm": 3.509353995323181e-05
    },
    {
      "step": 180,
      "train_loss": 7.099272775650024,
      "tokens_per_sec": 58662.05009889906,
      "lr_embedding": 9.046232700347899e-06,
      "lr_attention": 9.046232700347899e-06,
      "lr_ffn": 9.046232700347899e-06,
      "lr_norm": 9.046232700347899e-06
    },
    {
      "step": 200,
      "train_loss": 7.091057682037354,
      "tokens_per_sec": 58666.22678271945,
      "lr_embedding": 0.0,
      "lr_attention": 0.0,
      "lr_ffn": 0.0,
      "lr_norm": 0.0,
      "token_embedding.weight_spectral": 60.42732238769531,
      "layers.0.attention.qkv.weight_spectral": 1.0714507102966309,
      "layers.0.attention.out_proj.weight_spectral": 1.070403814315796,
      "layers.0.feed_forward.w1.weight_spectral": 1.0699615478515625,
      "layers.0.feed_forward.w2.weight_spectral": 1.0700809955596924,
      "layers.0.feed_forward.w3.weight_spectral": 1.0706405639648438,
      "layers.1.attention.qkv.weight_spectral": 1.0705924034118652,
      "layers.1.attention.out_proj.weight_spectral": 1.073484182357788,
      "layers.1.feed_forward.w1.weight_spectral": 1.0708670616149902,
      "layers.1.feed_forward.w2.weight_spectral": 1.070280909538269,
      "layers.1.feed_forward.w3.weight_spectral": 1.0696344375610352,
      "layers.2.attention.qkv.weight_spectral": 1.0695762634277344,
      "layers.2.attention.out_proj.weight_spectral": 1.07204008102417,
      "layers.2.feed_forward.w1.weight_spectral": 1.0689430236816406,
      "layers.2.feed_forward.w2.weight_spectral": 1.0712603330612183,
      "layers.2.feed_forward.w3.weight_spectral": 1.0700223445892334,
      "layers.3.attention.qkv.weight_spectral": 1.070565938949585,
      "layers.3.attention.out_proj.weight_spectral": 1.0712352991104126,
      "layers.3.feed_forward.w1.weight_spectral": 1.0713231563568115,
      "layers.3.feed_forward.w2.weight_spectral": 1.0699447393417358,
      "layers.3.feed_forward.w3.weight_spectral": 1.0709547996520996,
      "embedding_frob_mean": 116.8960952758789,
      "embedding_frob_max": 116.8960952758789,
      "attention_frob_mean": 21.44197988510132,
      "attention_frob_max": 21.472412109375,
      "ffn_frob_mean": 21.45172119140625,
      "ffn_frob_max": 21.460803985595703,
      "norm_frob_mean": 22.74313629998101,
      "norm_frob_max": 22.958362579345703
    },
    {
      "step": 200,
      "val_loss": 7.035319900512695,
      "perplexity": 1136.058279693993
    }
  ],
  "config": {
    "name": "stiefel_all",
    "description": "Stiefel manifold (W^T W = I) for attention & FFN",
    "max_steps": 200,
    "batch_size": 16,
    "hidden_size": 512,
    "num_layers": 4,
    "embedding_optimizer": "adamw",
    "embedding_lr": 0.0003,
    "attention_optimizer": "adamw",
    "attention_lr": 0.0003,
    "ffn_optimizer": "adamw",
    "ffn_lr": 0.0003
  },
  "final_val_loss": 7.042715120822825,
  "final_perplexity": 1144.490822783662,
  "end_time": "2025-12-06T08:39:24.175752"
}